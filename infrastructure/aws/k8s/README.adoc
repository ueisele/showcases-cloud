:toc:
:toc-title:
:toclevels: 2
:sectnums:

= Kubernetes Terraform Provisioning

== Apply Terraform

[source,bash]
----
terraform init -backend-config="profile=tu-dev-ueisele"
----

[source,bash]
----
terraform plan --var "profile=tu-dev-ueisele"
----

[source,bash]
----
terraform apply --var "profile=tu-dev-ueisele"
----

== Deployment Sizing

[source]
----
CoreDNS				            100m	 170Mi	2	x
EBS CSI Driver			      400m	 512Mi	1	x
EFS CSI Driver			      400m	 512Mi	1	x
IAM Auth Controller		     50m	  32Mi	1	x
LB Controller			        100m	 128Mi	1	x
External DNS Controller		 50m	  64Mi	1	x
Traefik Ingress           500m	 512Mi	3	x
Kube Metrics Server		    100m	 200Mi	2	x
Kubernetes Dashboard		  200m	 200Mi	2	x
Cluster Autoscaler		    100m	 512Mi	1	x
----

== Components

=== CoreDNS

=== EKS IAM Auth Controller

https://github.com/rustrial/aws-eks-iam-auth-controller

AWS EKS uses the link:https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html[aws-auth] ConfigMap in the kube-system namespace to map authenticated identities to Kubernetes username and groups (also see https://www.eksworkshop.com/beginner/091_iam-groups/test-cluster-access/).

You could authorize users and roles by manually modyfing the aws-auth ConfigMap:

.aws-auth.yaml
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - groups:
      - system:bootstrappers
      - system:nodes
      - system:node-proxier
      rolearn: ${EKS_FARGATE_PROFILE_ROLE_ARN}
      username: system:node:{{SessionName}}
    - groups:
      - system:bootstrappers
      - system:nodes
      rolearn: ${EKS_NODE_GROUP_ROLE_ARN}
      username: system:node:{{EC2PrivateDNSName}}
    - groups:
      - system:masters
      rolearn: ${K8SADMIN_ROLE_ARN}
      username: admin
  mapUsers: |
    - groups:
      - system:masters
      userarn: arn:aws:iam::${ACCOUNT_ID}:user/ueisele
      username: admin
----

[source,bash]
----
envsubst < aws-auth.yaml | kubectl apply -f -
----

However, using a single ConfigMap makes it hard and error prone to manage identity mappings using GitOps approach.

The link:https://github.com/rustrial/aws-eks-iam-auth-controller[EKS IAM Auth Controller] closes the gap by implementing a Custom Resource Controller, updating the aws-auth ConfigMap from IAMIdentityMapping objects. Once link:https://github.com/aws/containers-roadmap/issues/550[#550] or link:https://github.com/aws/containers-roadmap/issues/512[#512] is resolved this controller will no longer be needed.

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-eks-iam-auth-controller https://rustrial.github.io/aws-eks-iam-auth-controller
helm repo update
helm search repo aws-eks-iam-auth-controller
helm show values aws-eks-iam-auth-controller/rustrial-aws-eks-iam-auth-controller
----

=== EBS CSI Driver

https://github.com/kubernetes-sigs/aws-ebs-csi-driver

The EBS in-tree storage plugin, `kubernetes.io/aws-ebs` has been deprecated in favour of the `ebs.csi.aws.com` CSI driver.

.Default gp2 storage class
[source,yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  name: gp2
parameters:
  fsType: ext4
  type: gp2
provisioner: kubernetes.io/aws-ebs
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
----

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm repo update
helm search repo aws-ebs-csi-driver
helm show values aws-ebs-csi-driver/aws-ebs-csi-driver
----

=== EFS CSI Driver

https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm repo update
helm search repo aws-efs-csi-driver
helm show values aws-efs-csi-driver/aws-efs-csi-driver
----

=== AWS Load Balancer Controller

https://kubernetes-sigs.github.io/aws-load-balancer-controller

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add eks https://aws.github.io/eks-charts
helm repo update
helm search repo eks
helm show values eks/aws-load-balancer-controller
----

The AWS Load Balancer Controller is a provider for Ingress. Ingresses can be implemented by different controllers, often with different configuration.

Therefore, we need to create an IngressClass resource that contains additional configuration including the name of the controller that should implement the class (also see https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/).

The IngressClass is named `alb` and is defined as default.
So, after the IngressClass has been deployed, all created Ingress resources are managed by the AWS Load Balancer Controller.

The IngressClass sets link:https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/#specscheme[`scheme`] to `internal`, because in the K+N VPC, we have no public IP addresses.

In addition, it sets link:https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/#specgroup[`group`] to `default`, to add all Ingresses to the same AWS ALB.

.Verify that the IngressClass has been created
[source,bash]
----
kubectl get ingressClassParams alb
kubectl get ingressClass alb
----

=== Cluster Auto Scaler

https://docs.aws.amazon.com/de_de/eks/latest/userguide/cluster-autoscaler.html

*HINT*: WIP

The AWS Load Balancer Controller is configured with auto discovery. It automatically scales all EKS node groups with the following tags:

[source,yaml]
----
k8s.io/cluster-autoscaler/enabled: "true"
k8s.io/cluster-autoscaler/${aws_eks_cluster.main.name}: "owned"
----

== Next Steps

* Kubernetes Metrics Server: https://github.com/kubernetes-sigs/metrics-server
* Kubernetes Dashboard: https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/
* Cluster Autoscaler: https://docs.aws.amazon.com/de_de/eks/latest/userguide/cluster-autoscaler.html
* Security Groups for Pods: https://docs.aws.amazon.com/eks/latest/userguide/security-groups-for-pods.html
* Network Isolation with Calico: https://docs.aws.amazon.com/eks/latest/userguide/calico.html
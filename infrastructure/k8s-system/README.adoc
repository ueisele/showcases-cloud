:toc:
:toc-title:
:toclevels: 2
:sectnums:

= Terraform Kubernetes Provisioning

== Apply Terraform

Ensure you have the required link:required-iam-policy.json[IAM permissions].

[source,bash]
----
terraform init -backend-config="profile=${SHOWCASE_AWS_PROFILE}"
----

[source,bash]
----
terraform apply --var "profile=${SHOWCASE_AWS_PROFILE}"
----

== Components

=== CoreDNS

https://docs.aws.amazon.com/eks/latest/userguide/managing-coredns.html

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add coredns https://coredns.github.io/helm
helm repo update
helm show values coredns/coredns
helm search repo coredns
----

=== EKS IAM Auth Controller

https://github.com/rustrial/aws-eks-iam-auth-controller

AWS EKS uses the link:https://docs.aws.amazon.com/eks/latest/userguide/add-user-role.html[aws-auth] ConfigMap in the kube-system namespace to map authenticated identities to Kubernetes username and groups (also see https://www.eksworkshop.com/beginner/091_iam-groups/test-cluster-access/).

You could authorize users and roles by manually modyfing the aws-auth ConfigMap:

.aws-auth.yaml
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: aws-auth
  namespace: kube-system
data:
  mapRoles: |
    - groups:
      - system:bootstrappers
      - system:nodes
      - system:node-proxier
      rolearn: ${EKS_FARGATE_PROFILE_ROLE_ARN}
      username: system:node:{{SessionName}}
    - groups:
      - system:bootstrappers
      - system:nodes
      rolearn: ${EKS_NODE_GROUP_ROLE_ARN}
      username: system:node:{{EC2PrivateDNSName}}
    - groups:
      - system:masters
      rolearn: ${K8SADMIN_ROLE_ARN}
      username: admin
  mapUsers: |
    - groups:
      - system:masters
      userarn: arn:aws:iam::${ACCOUNT_ID}:user/ueisele
      username: admin
----

[source,bash]
----
envsubst < aws-auth.yaml | kubectl apply -f -
----

However, using a single ConfigMap makes it hard and error prone to manage identity mappings using GitOps approach.

The link:https://github.com/rustrial/aws-eks-iam-auth-controller[EKS IAM Auth Controller] closes the gap by implementing a Custom Resource Controller, updating the aws-auth ConfigMap from IAMIdentityMapping objects. Once link:https://github.com/aws/containers-roadmap/issues/550[#550] or link:https://github.com/aws/containers-roadmap/issues/512[#512] is resolved this controller will no longer be needed.

Terraform automatically creates IAM identity mappings for users specified in the variable `k8s_admin_users`.

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-eks-iam-auth-controller https://rustrial.github.io/aws-eks-iam-auth-controller
helm repo update
helm show values aws-eks-iam-auth-controller/rustrial-aws-eks-iam-auth-controller
helm search repo aws-eks-iam-auth-controller
----

=== EBS CSI Driver

https://github.com/kubernetes-sigs/aws-ebs-csi-driver

The EBS in-tree storage plugin, `kubernetes.io/aws-ebs` has been deprecated in favour of the `ebs.csi.aws.com` CSI driver.

.Default gp2 storage class
[source,yaml]
----
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
  name: gp2
parameters:
  fsType: ext4
  type: gp2
provisioner: kubernetes.io/aws-ebs
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
----

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-ebs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm repo update
helm show values aws-ebs-csi-driver/aws-ebs-csi-driver
helm search repo aws-ebs-csi-driver
----

=== EFS CSI Driver

https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-ebs-csi-driver
helm repo update
helm show values aws-efs-csi-driver/aws-efs-csi-driver
helm search repo aws-efs-csi-driver
----

=== AWS Load Balancer Controller

https://kubernetes-sigs.github.io/aws-load-balancer-controller

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add eks https://aws.github.io/eks-charts
helm repo update
helm show values eks/aws-load-balancer-controller
helm search repo eks
----

The AWS Load Balancer Controller is a provider for Ingress. Ingresses can be implemented by different controllers, often with different configuration.

Therefore, we need to create an IngressClass resource that contains additional configuration including the name of the controller that should implement the class (also see https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/).

The IngressClass is named `alb` and is defined as default.
So, after the IngressClass has been deployed, all created Ingress resources are managed by the AWS Load Balancer Controller.

The IngressClass sets link:https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/#specscheme[`scheme`] to `internal`, because in the K+N VPC, we have no public IP addresses.

In addition, it sets link:https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.3/guide/ingress/ingress_class/#specgroup[`group`] to `default`, to add all Ingresses to the same AWS ALB.

.Verify that the IngressClass has been created
[source,bash]
----
kubectl get ingressClassParams alb
kubectl get ingressClass alb
----

=== External DNS

https://github.com/kubernetes-sigs/external-dns/tree/master/charts/external-dns

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add external-dns https://kubernetes-sigs.github.io/external-dns/
helm repo update
helm show values external-dns/external-dns
helm search repo external-dns
----

=== Traefik

https://github.com/traefik/traefik-helm-chart

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add traefik https://helm.traefik.io/traefik
helm repo update
helm show values traefik/traefik
helm search repo traefik
----

For simple authentication a middleware with name `basic-auth-default` is created.

.Example for authentication with basic auth
[source,yaml]
----
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: web
    traefik.ingress.kubernetes.io/router.middlewares: kube-system-basic-auth-default@kubernetescrd
----

.Determine credentials
[source,bash]
----
terraform output --raw traefik_basic_auth_default_credentials
----

Services:

* Traefik Dashboard: https://traefik.ada.letuscode.dev/

=== Cluster Auto Scaler

https://docs.aws.amazon.com/de_de/eks/latest/userguide/cluster-autoscaler.html

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add autoscaler https://kubernetes.github.io/autoscaler
helm repo update
helm show values autoscaler/cluster-autoscaler
helm search repo autoscaler
----

The configuration parameters are described at: https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-are-the-parameters-to-ca

The Cluster Auto Scaler is configured with auto discovery. It automatically scales all EKS node groups with the following tags:

[source,yaml]
----
k8s.io/cluster-autoscaler/enabled: "true"
k8s.io/cluster-autoscaler/${aws_eks_cluster.main.name}: "owned"
----

=== Kube Metrics Server

https://github.com/kubernetes-sigs/metrics-server

At the moment, the link:https://github.com/kubernetes-sigs/metrics-server/tree/master/charts[`metrics-server`] Helm chart is maintained localy at link:charts/metrics-server[charts/metrics-server]. If the Helm chart for version _0.6.0_ has been released, the chart could be used from repository https://kubernetes-sigs.github.io/metrics-server.

You can check for the latest versions and print the default _values.yaml_ with the following commands:

[source,bash]
----
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server
helm repo update
helm show values metrics-server/metrics-server
helm search repo metrics-server 
----

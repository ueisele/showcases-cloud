= Confluent Platform with Kerberos AuthZ and AuthZ

The goal of the example is to demonstrate authentication and authorization with Kerberos and RBAC on the external listener. Confluent will be connected to an AD with domain `ada.letuscode.xyz` and uses this as identity provider. Which permissions a user has is defined in Confluent MDS based on role bindings to groups.

*HINT*: This example is based on the link:../ldap[ldap] example.

*IMPORTANT*: This example requires the Confluent Enterprise edition, because RBAC and LDAP authentication are not suppored by the Open Source edition.

*NOTE*: The Kubernetes manifests are based on the link:https://github.com/confluentinc/cp-helm-charts[Confluent Helm Charts].

*IMPORTANT*:

* Kerberos authentication is an option for Kafka broker. It is possible to authenticate users from the local as well as from other remote ADs. 
* Kerberos requires that services are registered on a domain which matches their hostname. This is typically not the case for services running in Kubernetes. There are workarounds like adding SPNs to user prinicpals. However, especially cross domain authentication may fail, because no realm for the service like Kafka exists. Kerberos is not recommended for services running in Kubernetes. Mechanisms like OIDC are preferable.
* Kerberos authentication is not supported for MDS user authentication. MDS always performs an LDAP search of the local LDAP and performs an simple bind of the corresponding users. If an user is maintained in another AD it cannot be found. Therefore Confluent components like Control Center will not support authentication of users from other domains.

== Prerequisites

=== Domain `ADA.LETUSCODE.XYZ`

This example requires link:../../../infrastructure/ldap[infrastructure/ldap] and link:../../../infrastructure/ec2-windows[infrastructure/ec2-windows] to be installed.

Connetc via RDP to the Windows EC2 instanced for `ada.letuscode.xyz` and create the following users and groups:

`ou=Users,ou=ada,dc=ada,dc=letuscode,dc=xyz`:

* mds
* kafka
* kafkarest
* app_geysers

`ou=Groups,ou=ada,dc=ada,dc=letuscode,dc=xyz`:

* team_enceladus

Add user `app_geysers` to group `team_enceladus`.

=== Domain `com.codelabs.dev`

Connetc via RDP to the Windows EC2 instanced for
`com.codelabs.dev` and create the following users and groups:

`ou=Users,ou=com,dc=com,dc=codelabs,dc=dev`:

* ada.lovelace
* grace.hopper

== Deployment

.Create the Kubernetes namespace for this example:
[source,bash]
----
kubectl apply -f namespace.yaml
----

=== CLIs

.Deploy CLIs:
[source,bash]
----
kubectl apply -f cli
----

=== ZooKeeper

.Deploy ZooKeeper:
[source,bash]
----
kubectl apply -f cluster/zookeeper.yaml
----

=== Kafka

Before Kafka can be deployed, additional manual steps are required.

* Creation of Kerberos keytab file to allow MDS to authenticate with LDAP without password
* Adjust the Kerberos hostnames in the kafka.yaml file
* Creation of keypair for MDS for token signing
* Creation of credentials for Kafka Rest to authenticate with MDS
* Creation of principals for GSSAPI Kerberos authentication on Kafka listener

==== Create Kerberos Keytab File for MDS

The link:https://docs.oracle.com/cd/E19683-01/806-4078/6jd6cjs1l/index.html[keytab] is a local file that stores the principal for LDAP, as well as a timestamp, a key version number, and the encrypted keys. In this context, keyTab is used to authenticate Kerberos with the LDAP server without having to explicitly enter a password. 

For more information have a look at the Confluent documentation about link:https://docs.confluent.io/platform/current/security/ldap-authorization/configuration.html#configuring-gssapi-for-ldap[Configuring GSSAPI for LDAP].
The following excerpt shows the Kafka MDS configuration which references th keytab file.

[source,properties]
----
# Configure SASL/GSSAPI as the authentication protocol for LDAP context.
ldap.java.naming.security.authentication=GSSAPI
# Security principal for LDAP context
ldap.java.naming.security.principal=mds@ADA.LETUSCODE.XYZ
# JAAS configuration for Kerberos authentication with LDAP server
ldap.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
  keyTab="/mnt/secrets/mds-keytab/mds.ada.letuscode.xyz.keytab" \
  principal="mds@ADA.LETUSCODE.XYZ" \
  storeKey="true" \
  useKeyTab="true";
----

Now lets create the Kerberos keytab file.

.Exec into the LDAP Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli -o name) bash
----

From the command line type `ktutil` to launch the utility.

.Type the following command to add `mds` user to the keytab.
[source,bash]
----
addent -password -p mds -k 1 -e RC4-HMAC
----

When prompted, enter the password for the Kerberos principal user. 

.Type the following command to create a keytab.
[source,bash]
----
wkt /tmp/mds.ada.letuscode.xyz.keytab
----

Finally, type `q` tp quit the ktutil utility.

.You can view the principal in the keytab using the klist command.
[source,bash]
----
klist -kt /tmp/mds.ada.letuscode.xyz.keytab
----

.Now check if you can authenticate with the keytab file
[source,bash]
----
export KRB5CCNAME=/tmp/mds.ada.letuscode.xyz.cc.tmp
kinit mds@ADA.LETUSCODE.XYZ -kt /tmp/mds.ada.letuscode.xyz.keytab -c ${KRB5CCNAME}
----

If you type `klist` it should print an output similar to this:

----
Ticket cache: FILE:/tmp/mds.ada.letuscode.xyz.cc.tmp
Default principal: mds@ADA.LETUSCODE.XYZ

Valid starting     Expires            Service principal
02/13/22 18:13:45  02/14/22 04:13:45  krbtgt/ADA.LETUSCODE.XYZ@ADA.LETUSCODE.XYZ
----

.Copy the keytab file to your local machine.
[source,bash]
----
mkdir -p security/keytab
kubectl -n confluent-kerberos cp $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli --template '{{range .items}}{{.metadata.name}}{{end}}'):/tmp/mds.ada.letuscode.xyz.keytab security/keytab/mds.ada.letuscode.xyz.keytab
----

.Create a Kubernetes secret with the keytab file
[source,bash]
----
kubectl create secret generic mds-keytab \
    --from-file=mds.ada.letuscode.xyz.keytab=security/keytab/mds.ada.letuscode.xyz.keytab \
    --namespace confluent-kerberos
kubectl -n confluent-kerberos label secret mds-keytab app.kubernetes.io/instance=confluent
----

==== Adjust the AD/Kerberos Hostnames in the kafka.yaml

It is important that the real names of the domain controllers are used for authentication via Kerberos. Addidional CNAMEs like `ada.letuscode.xyz` will not work!

Therefore, at the moment, the actual domain controler names are specified in the link:cluster/kafka.yaml[cluster/kafka.yaml] file.
Before you start, ensure that this domain controller names and IP addresses are correct.

.Exec into the LDAP Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli -o name) bash
----

.Query the domain controllers for `ada.letuscode.xyz``
[source,bash]
----
> nslookup -type=srv _ldap._tcp.dc._msdcs.ada.letuscode.xyz
Server:         172.20.0.10
Address:        172.20.0.10:53

Non-authoritative answer:
_ldap._tcp.dc._msdcs.ada.letuscode.xyz  service = 0 100 389 win-8sgn1ju6kut.ada.letuscode.xyz
_ldap._tcp.dc._msdcs.ada.letuscode.xyz  service = 0 100 389 win-0lu0jt0n3fk.ada.letuscode.xyz
----

*NOTE*: Because the hostnames are dynamically created when the AWS Directory AD is created, this solution is impractible to some extend. We would like to use a generic name like `ada.letuscode.xyz` for the AD. Especially to not depend on a single instance for connection. For now we accept this, but we should investigate other solutions to overcome this. Kerberos works with SPNs (Service Principle Names) for authorization. By default for a service like AD there exists one with the exact hostname (e.g `ldap/win-8sgn1ju6kut.ada.letuscode.xyz@ADA.LETUSCODE.XYZ`). However its also possible to create additional SPNs, so it could work if we add an additional SPN per domain controller with the name `ldap/ada.letuscode.xyz@ADA.LETUSCODE.XYZ`.

==== Create MDS Keypair

.Create the Kubernetes secret with a keypair which will be used by MDS for token signing.
[source,bash]
----
./create-keys.sh
./btpl security/mds-token.btpl.yaml | kubectl apply -f -
----

==== Create Credentials for Kafka Rest

.Create the Kubernetes secret for Kafka Rest MDS authentication.
[source,bash]
----
export KAFKAREST_USERNAME='kafkarest@ada.letuscode.xyz'
export KAFKAREST_PASSWORD='my_kafkarest_password'
./btpl security/kafkarest-credentials.btpl.yaml | kubectl apply -f -
----

==== Creation of Principals for GSSAPI Kerberos Authentication on Kafka Listener

https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_gssapi.html#kafka-sasl-auth-gssapi

For each Kafka broker hostname, to which a client connects, a SPN (Service Principal Name) is required.

Connect to a Windows EC2 Instance which is connected to domain `ada.letuscode.xyz` and open PowerShell.

Because the Kafka brokers are not registerd as computers on our Domain, we set SPNs for each broker hostname on the `kafka` user.

*TODO:* I did not check if it also works without the SPNs. The assumption is that they are required, but it should be checked if it also works without them.

[source,powershell]
----
setspn -U -S kafka/kafka kafka
setspn -U -S kafka/kafka.confluent-kerberos.svc.cluster.local kafka
setspn -U -S kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local kafka
setspn -U -S kafka/kafka-1.kafka-headless.confluent-kerberos.svc.cluster.local kafka
setspn -U -S kafka/kafka-2.kafka-headless.confluent-kerberos.svc.cluster.local kafka
----

[source,powershell]
----
setspn -U -L kafka
----

----
Registered ServicePrincipalNames for CN=kafka,OU=Users,OU=ada,DC=ada,DC=letuscode,DC=xyz:
        kafka/kafka-2.kafka-headless.confluent-kerberos.svc.cluster.local
        kafka/kafka-1.kafka-headless.confluent-kerberos.svc.cluster.local
        kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local
        kafka/kafka.confluent-kerberos.svc.cluster.local
        kafka/kafka
----

Now, it is possible to request tickets for those SPNs.

[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli -o name) bash
----

[source,bash]
----
kinit admin@ADA.LETUSCODE.XYZ
kvno kafka
kvno kafka/kafka@ADA.LETUSCODE.XYZ
kvno kafka/kafka.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ
kvno kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ
kvno kafka/kafka-1.kafka-headless.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ
kvno kafka/kafka-2.kafka-headless.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ
----

----
kafka@ADA.LETUSCODE.XYZ: kvno = 2
----

Note the `kvno` which is 3 in this case. This key version is required for the keytab file (also see link:https://www.oreilly.com/library/view/kerberos-the-definitive/0596004036/ch03s02s03.html[The Key Version Number]).

Now lets create the Kerberos keytab file with the SPNs for the Kafka brokers.

.First remove the existing Kerberos tickets (logout)
[source,bash]
----
kdestroy
----

From the command line type `ktutil` to launch the utility.

.Type the following command to add `kafka` user to the keytab (ensure that -k is set to the `kvno` value, e.g. -k 2)
[source,bash]
----
addent -password -p kafka -k 2 -e RC4-HMAC
----

When prompted, enter the password for the Kerberos service principal, which is the same as for the corresponding user which is `kafka` in this case.

**NOTE:** `kafka/kafka` has nothing to do with the user principal to which the SPNs has been added. The meaning is `{service}/{hostname}`. The name of the service is defined at the Kafka broker with the config:

[source,yaml]
----
- name: KAFKA_SASL_KERBEROS_SERVICE_NAME
  value: kafka
----

.Type the following command to create a keytab
[source,bash]
----
wkt /tmp/kafka.ada.letuscode.xyz.keytab
----

Finally, type `q` to quit the ktutil utility.

.You can view the service principals in the keytab using the klist command
[source,bash]
----
klist -kt /tmp/kafka.ada.letuscode.xyz.keytab
----

.Now check if you can authenticate with the keytab file
[source,bash]
----
export KRB5CCNAME=/tmp/kafka.ada.letuscode.xyz.cc.tmp
kinit kafka@ADA.LETUSCODE.XYZ \
    -S kafka/kafka.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ \
    -kt /tmp/kafka.ada.letuscode.xyz.keytab \
    -c ${KRB5CCNAME}
----

If you type `klist` it should see an ticket for SPN `kafka/kafka.confluent-kerberos.svc.cluster.local@ADA.LETUSCODE.XYZ`.

.Copy the keytab file to your local machine
[source,bash]
----
mkdir -p security/keytab
kubectl -n confluent-kerberos cp $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli --template '{{range .items}}{{.metadata.name}}{{end}}'):/tmp/kafka.ada.letuscode.xyz.keytab security/keytab/kafka.ada.letuscode.xyz.keytab -c ldap-cli
----

.Create a Kubernetes secret with the keytab file
[source,bash]
----
kubectl create secret generic kafka-keytab \
    --from-file=kafka.ada.letuscode.xyz.keytab=security/keytab/kafka.ada.letuscode.xyz.keytab \
    --namespace confluent-kerberos
kubectl -n confluent-kerberos label secret kafka-keytab app.kubernetes.io/instance=confluent
----

==== Deploy Kafka

.Deploy Kafka brokers:
[source,bash]
----
kubectl apply -f cluster/kafka.yaml
----

=== Undeployment

.Finaly, if you are done with everything, undeploy it:
[source,bash]
----
kubectl delete -f clie
kubectl delete -f cluster
kubectl -n confluent-kerberos delete secret -l app.kubernetes.io/instance=confluent
kubectl -n confluent-kerberos delete pvc -l app.kubernetes.io/instance=confluent
kubectl delete -f namespace.yaml
----

== Verify Kafka AuthN & AuthZ

=== Verify AuthN with Kerberos and KafkaCat

*NOTE:* GSSAPI only works if in the `confluentinc/cp-kafkacat` image also `cyrus-sasl` and `cyrus-sasl-gssapi` packages are installed.

*NOTE:* GSSAPI only works with a proper configured /etc/krb5.cfg file. This file is mounted as a config map to the cli container.

.Exec into the KafkaCat Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafkacat-cli -o name) bash
----

.Set admin credentials
[source,bash]
----
export ADMIN_USERNAME=admin
export ADMIN_PASSWORD='my_admin_password'
----

.Query Metadata with SASL/PLAIN
[source,bash]
----
kafkacat -b kafka:9092 -L \
    -X security.protocol=sasl_plaintext \
    -X sasl.mechanisms=PLAIN \
    -X sasl.username=${ADMIN_USERNAME} \
    -X sasl.password=${ADMIN_PASSWORD}
----

.Query Metadata with SASL/GSSAPI
[source,bash]
----
kafkacat -b kafka:9092 -L \
    -X security.protocol=sasl_plaintext \
    -X sasl.mechanisms=GSSAPI \
    -X sasl.kerberos.service.name=kafka \
    "-Xsasl.kerberos.kinit.cmd=echo ${ADMIN_PASSWORD} | kinit ${ADMIN_USERNAME}"
----

.Consume from Topic with SASL/GSSAPI
[source,bash]
----
kafkacat -b kafka:9092 -C -t _confluent-metrics \
    -X security.protocol=sasl_plaintext \
    -X sasl.mechanisms=GSSAPI \
    -X sasl.kerberos.service.name=kafka \
    "-Xsasl.kerberos.kinit.cmd=echo ${ADMIN_PASSWORD} | kinit ${ADMIN_USERNAME}"
----

=== Verify AuthN with Kerberos and Kafka Java CLI Tools

*NOTE:* GSSAPI only works with a proper configured /etc/krb5.cfg file. This file is mounted as a config map to the cli container.

==== Create keytab file for `admin` user

[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli -o name) bash
----

From the command line type `ktutil` to launch the utility.

.Type the following command to add `admin` user to the keytab.
[source,bash]
----
addent -password -p admin -k 1 -e RC4-HMAC
----

.Type the following command to create a keytab.
[source,bash]
----
wkt /tmp/admin.ada.letuscode.xyz.keytab
----

Finally, type `q` to quit the ktutil utility.

.You can view the service principals in the keytab using the klist command.
[source,bash]
----
klist -kt /tmp/admin.ada.letuscode.xyz.keytab
----

.Now check if you can authenticate with the keytab file.
[source,bash]
----
export KRB5CCNAME=/tmp/admin.ada.letuscode.xyz.cc.tmp
kinit admin@ADA.LETUSCODE.DEV \
    -kt /tmp/admin.ada.letuscode.xyz.keytab \
    -c ${KRB5CCNAME}
----

.Copy the keytab file to your local machine.
[source,bash]
----
mkdir -p security/keytab
kubectl -n confluent-kerberos cp $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=ldap-cli --template '{{range .items}}{{.metadata.name}}{{end}}'):/tmp/admin.ada.letuscode.xyz.keytab security/keytab/admin.ada.letuscode.xyz.keytab -c ldap-cli
----

.Create a Kubernetes secret with the keytab file.
[source,bash]
----
kubectl create secret generic admin-keytab \
    --from-file=admin.ada.letuscode.xyz.keytab=security/keytab/admin.ada.letuscode.xyz.keytab \
    --namespace confluent-kerberos
kubectl -n confluent-kerberos label secret admin-keytab app.kubernetes.io/instance=confluent
----

==== Use the Keytab file with the Kafka CLI tools

.Copy the keytab file to the Kafka Cli Pod.
[source,bash]
----
kubectl -n confluent-kerberos cp security/keytab/admin.ada.letuscode.xyz.keytab $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli --template '{{range .items}}{{.metadata.name}}{{end}}'):/tmp/admin.ada.letuscode.xyz.keytab
----

.Exec into the Kafka Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli -o name) bash
----

.Create client config for `admin` super user
[source,bash]
----
cat > admin.config << EOF
sasl.mechanism=GSSAPI
security.protocol=SASL_PLAINTEXT
sasl.kerberos.service.name=kafka
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
    useKeyTab=true \
    storeKey=true \
    keyTab="/tmp/admin.ada.letuscode.xyz.keytab" \
    principal="admin@ADA.LETUSCODE.DEV";
EOF
----

.List topics with `admin` super user
[source,bash]
----
kafka-topics --command-config admin.config --bootstrap-server kafka:9092 --list
----

==== Use the Ticket Cache with the Kafka CLI tools

.Exec into the Kafka Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli -o name) bash
----

.Create client config which uses the Kerberos ticket cache
[source,bash]
----
cat > gssapi-tc.config << EOF
sasl.mechanism=GSSAPI
security.protocol=SASL_PLAINTEXT
sasl.kerberos.service.name=kafka
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useTicketCache=true;
EOF
----

.Login with user admin
[source,bash]
----
kinit admin@ADA.LETUSCODE.XYZ
----

.List topics with user currently authenticated user
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

.Login with user `app_geysers`
[source,bash]
----
kinit app_geysers@ADA.LETUSCODE.DEV
----

.List topics with `app_geysers` user
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

This is a valid user, but has no permissions. Therefore no topics are
listed.

=== Create Kafka Role Bindings for Group `team_enceladus` to verify AuthZ 

.Exec into the Confluent Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=confluent-cli -o name) bash
----

.Login with super user `admin`
[source,bash]
----
confluent login
----

.Resolve Cluster Id
[source,bash]
----
apk add jq
export CLUSTER_ID="$(confluent cluster describe -o json | jq -r .crn)"
----

.Create Role Bindings for group `team_enceladus`
[source,bash]
----
confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperManage \
    --resource Topic:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperWrite \
    --resource Topic:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperRead \
    --resource Topic:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperManage \
    --resource Group:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID
    
confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperRead \
    --resource Group:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal Group:team_enceladus \
    --role DeveloperWrite \
    --resource Group:enceladus_ \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID
----

.List created role bindings
[source,bash]
----
confluent iam rbac role-binding list --kafka-cluster-id $CLUSTER_ID --principal Group:team_enceladus
----

.Exec into the Kafka Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli -o name) bash
----

.Login with user `app_geysers`
[source,bash]
----
kinit app_geysers@ADA.LETUSCODE.DEV
----

.List topics with `app_geysers` user
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

This is a valid user, but has only permissions for topics prefixed with `enceladus_`.

.Create an topic with name `enceladus_app1`
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 \
        --create --topic enceladus_app1 --replication-factor 3 --partitions 3
----

.Try to create an topic with name `another-app1`
[source,bash]
----
kafka-topics --command-config app.config --bootstrap-server kafka:9092 \
        --create --topic another-app1 --replication-factor 3 --partitions 3
----

The user `app_geysers` was only able to create the topic with the name `enceladus_app1`.

.Publish a message to topic `enceladus_app1`
[source,bash]
----
echo "test_message" | kafka-console-producer \
    --broker-list kafka:9092 \
    --topic enceladus_app1 \
    --producer.config gssapi-tc.config \
    --property parse.key=false
----

.Consume a message from topic `enceladus_app1` with consumer group `enceladus_app1_cg`
[source,bash]
----
kafka-console-consumer \
    --bootstrap-server kafka:9092 \
    --topic enceladus_app1 \
    --group enceladus_app1_cg \
    --consumer.config gssapi-tc.config  \
    --from-beginning \
    --property parse.key=false \
    --max-messages 1
----

== Verify Kafka AuthN & AuthZ (Foreign Domain)

=== Verify AuthN with Kerberos

.Exec into the Kafka Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli -o name) bash
----

.Login with user `florian.eisele`
[source,bash]
----
kinit florian.eisele@COM.CODELABS.DEV
----

.Create client config which uses the Kerberos ticket cache
[source,bash]
----
cat > gssapi-tc.config << EOF
sasl.mechanism=GSSAPI
security.protocol=SASL_PLAINTEXT
sasl.kerberos.service.name=kafka
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useTicketCache=true;
EOF
----

.List topics with `florian.eisele` user
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

The user is authenticated, but has no permissions to list any topics.

=== Deep Dive Kerberos Authentication Flow

==== Client

.Inital authentication to get ticket from KDC
[source,bash]
----
kinit florian.eisele@COM.CODELABS.DEV
----

----
AS-REQ -> AD COM.CODELABS.DEV
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: florian.eisele
  sname:
    type: kRB5-NT-SRV-INST
    sname: krbtgt/COM.CODELABS.DEV
AS-REP <- AD COM.CODELABS.DEV
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: florian.eisele
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/COM.CODELABS.DEV
    cipher: 129fb0e61b...
----

.Request topics from Kafka by using previously acquired ticket
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

*In order to contact Kafka bootstrap broker request service ticket for it*

Service: kafka/kafka.confluent-kerberos.svc.cluster.local@ada.letuscode.xyz

----
TGS-REQ -> AD COM.CODELABS.DEV
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/COM.CODELABS.DEV
    cipher: 129fb0e61b...
  sname:
    type: kRB5-NT-SRV-INST
    sname: krbtgt/ada.letuscode.xyz
TGS-REP <- AD COM.CODELABS.DEV
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/ada.letuscode.xyz
    cipher: 3af81c7257...
----

----
TGS-REQ -> AD ada.letuscode.xyz
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/ada.letuscode.xyz
    cipher: 3af81c7257...
  sname:
    type: kRB5-NT-UNKNOWN
    sname: kafka/kafka.confluent-kerberos.svc.cluster.local
TGS-REP <- AD ada.letuscode.xyz
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: florian.eisele
  ticket:
    sname:
    type: kRB5-NT-UNKNOWN
    sname: kafka/kafka.confluent-kerberos.svc.cluster.local
    cipher: 2963d33aa8...
----

*In order to contact actual Kafka broker request service ticket for it*

Service: kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local@ada.letuscode.xyz

----
TGS-REQ -> AD COM.CODELABS.DEV
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/COM.CODELABS.DEV
    cipher: 129fb0e61b...
  sname:
    type: kRB5-NT-SRV-INST
    sname: krbtgt/ada.letuscode.xyz
TGS-REP <- AD COM.CODELABS.DEV
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/ada.letuscode.xyz
    cipher: b98a0c3e88...
----

----
TGS-REQ -> AD ada.letuscode.xyz
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/ada.letuscode.xyz
    cipher: b98a0c3e88...
  sname:
    type: kRB5-NT-UNKNOWN
    sname: kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local
TGS-REP <- AD ada.letuscode.xyz
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: florian.eisele
  ticket:
    sname:
    type: kRB5-NT-UNKNOWN
    sname: kafka/kafka-0.kafka-headless.confluent-kerberos.svc.cluster.local
    cipher: 789ea1a570...
----

==== Broker

*On Kafka broker startup it authenticates with the KDC with its Keytab file*

----
AS-REQ -> AD ada.letuscode.xyz
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: kafka
  sname:
    type: kRB5-NT-SRV-INST
    sname: krbtgt/ada.letuscode.xyz
AS-REP <- AD ada.letuscode.xyz
  cname:
    type: kRB5-NT-PRINCIPAL
    cname: kafka
  ticket:
    sname:
      type: kRB5-NT-SRV-INST
      sname: krbtgt/ada.letuscode.xyz
    cipher: 6eda5904fe...
----

*When the client connects with its ticket the broker can validate without connection to KDC*

----
[2022-02-16 07:54:47,103] TRACE connections.max.reauth.ms for mechanism=PLAIN: 0 (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,103] TRACE connections.max.reauth.ms for mechanism=GSSAPI: 0 (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,169] DEBUG Set SASL server state to HANDSHAKE_OR_VERSIONS_REQUEST during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,169] DEBUG Handling Kafka request API_VERSIONS during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,170] DEBUG Set SASL server state to HANDSHAKE_REQUEST during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,171] DEBUG Handling Kafka request SASL_HANDSHAKE during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,171] DEBUG Using SASL mechanism 'GSSAPI' provided by client (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
[2022-02-16 07:54:47,171] DEBUG Creating SaslServer for kafka@ada.letuscode.xyz with mechanism GSSAPI (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
Found KeyTab /mnt/secrets/kafka-keytab/kafka.ada.letuscode.xyz.keytab for kafka@ada.letuscode.xyz
Found KeyTab /mnt/secrets/kafka-keytab/kafka.ada.letuscode.xyz.keytab for kafka@ada.letuscode.xyz
Found ticket for kafka@ada.letuscode.xyz to go to krbtgt/ada.letuscode.xyz@ada.letuscode.xyz expiring on Wed Feb 16 12:42:15 GMT 2022
[2022-02-16 07:54:47,172] DEBUG Set SASL server state to AUTHENTICATE during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
Entered Krb5Context.acceptSecContext with state=STATE_NEW
Looking for keys for: kafka@ada.letuscode.xyz
Added key: 23version: 3
>>> EType: sun.security.krb5.internal.crypto.ArcFourHmacEType
Using builtin default etypes for permitted_enctypes
default etypes for permitted_enctypes: 18 17 20 19 16 23.
>>> EType: sun.security.krb5.internal.crypto.ArcFourHmacEType
MemoryCache: add 1644998087/204572/47D0CD7CC958801981F9DD40897B42286AC8973AB6F69A7FBDFC67AA2DCB62DB/florian.eisele@COM.CODELABS.DEV to florian.eisele@COM.CODELABS.DEV|kafka/kafka-0.kafka-headless.confluent-k>
>>> KrbApReq: authenticate succeed.
Krb5Context setting peerSeqNumber to: 309214781
Krb5Context setting mySeqNumber to: 309214781
Krb5Context.wrap: data=[01 01 00 00 ]
Krb5Context.wrap: token=[60 30 06 09 2a 86 48 86 f7 12 01 02 02 02 01 11 00 ff ff ff ff b3 1c 1b f5 6b 14 e3 b0 2e c4 f8 bd 17 29 52 a6 55 68 18 6a 08 4c cf f0 01 01 00 00 01 ]
Krb5Context.unwrap: token=[60 52 06 09 2a 86 48 86 f7 12 01 02 02 02 01 11 00 ff ff ff ff f0 e9 d0 1f d3 09 26 24 b0 b9 72 fc 0e e1 fc b1 ec 89 df 14 36 3d 3d 41 01 00 00 00 63 61 72 65 6c 6f 67 2d 75 73 65 72 40 >
Krb5Context.unwrap: data=[01 00 00 00 63 61 72 65 6c 6f 67 2d 75 73 65 72 40 41 55 54 48 2d 43 4f 4e 46 4c 55 45 4e 54 2e 4d 45 50 2e 4b 4e ]
[2022-02-16 07:54:47,210] INFO Successfully authenticated client: authenticationID=florian.eisele@COM.CODELABS.DEV; authorizationID=florian.eisele@COM.CODELABS.DEV. (org.apache.kafka.common.security.authenti>
[2022-02-16 07:54:47,210] DEBUG Authentication complete; session max lifetime from broker config=0 ms, no credential expiration; no session expiration, sending 0 ms to client (org.apache.kafka.common.security.auth>
[2022-02-16 07:54:47,210] DEBUG Set SASL server state to COMPLETE during authentication (org.apache.kafka.common.security.authenticator.SaslServerAuthenticator)
----

=== Create Role bindings for user `florian.eisele`

.Exec into the Confluent Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=confluent-cli -o name) bash
----

.Login with super user `admin`
[source,bash]
----
confluent login
----

.Resolve Cluster Id
[source,bash]
----
apk add jq
export CLUSTER_ID="$(confluent cluster describe -o json | jq -r .crn)"
----

.Create Role Bindings for user `florian.eisele`
[source,bash]
----
confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperManage \
    --resource Topic:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperWrite \
    --resource Topic:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperRead \
    --resource Topic:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperManage \
    --resource Group:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperRead \
    --resource Group:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID

confluent iam rbac role-binding create \
    --principal User:florian.eisele \
    --role DeveloperWrite \
    --resource Group:fe- \
    --prefix \
    --kafka-cluster-id $CLUSTER_ID
----

.List created role bindings
[source,bash]
----
confluent iam rbac role-binding list --kafka-cluster-id $CLUSTER_ID --principal User:florian.eisele
----

.Exec into the Kafka Cli pod
[source,bash]
----
kubectl -n confluent-kerberos exec -it $(kubectl -n confluent-kerberos get pods -l app.kubernetes.io/name=kafka-cli -o name) bash
----

.Login with user `florian.eisele`
[source,bash]
----
kinit florian.eisele@COM.CODELABS.DEV
----

.List topics with `florian.eisele` user
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 --list
----

This is a valid user, but has only permissions for topics prefixed with `fe-`.

.Create an topic with name `fe-app1`
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 \
        --create --topic fe-app1 --replication-factor 3 --partitions 3
----

.Try to create an topic with name `another-app1`
[source,bash]
----
kafka-topics --command-config gssapi-tc.config --bootstrap-server kafka:9092 \
        --create --topic another-app1 --replication-factor 3 --partitions 3
----

The user `florian.eisele` was only able to create the topic with the name `fe-app1`.

.Publish a message to topic `fe-app1`
[source,bash]
----
echo "test_message" | kafka-console-producer \
    --broker-list kafka:9092 \
    --topic fe-app1 \
    --producer.config gssapi-tc.config \
    --property parse.key=false
----

.Consume a message from topic `fe-app1` with consumer group `fe-app1-cg`
[source,bash]
----
kafka-console-consumer \
    --bootstrap-server kafka:9092 \
    --topic fe-app1 \
    --group fe-app1-cg \
    --consumer.config gssapi-tc.config  \
    --from-beginning \
    --property parse.key=false \
    --max-messages 1
----
